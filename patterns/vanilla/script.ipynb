{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install \\\n",
    "  transformers \\\n",
    "  sentence-transformers \\\n",
    "  pinecone-client \\\n",
    "  datasets \\\n",
    "  accelerate \\\n",
    "  einops \\\n",
    "  langchain \\\n",
    "  xformers \\\n",
    "  bitsandbytes \\\n",
    "  langchain-community \\\n",
    "  pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install git+https://github.com/naver/splade.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize HG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import cuda\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embed_model_id = 'sentence-transformers/msmarco-bert-base-dot-v5'\n",
    "\n",
    "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
    "\n",
    "embed_model = HuggingFaceEmbeddings(\n",
    "    model_name=embed_model_id,\n",
    "    model_kwargs={'device': device},\n",
    "    encode_kwargs={'device': device, 'batch_size': 32}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Pinecone index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import os\n",
    "\n",
    "pc = Pinecone(api_key='XXX')\n",
    "index_name = 'bigvul-single-ctx'\n",
    "\n",
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=768, \n",
    "    metric=\"dotproduct\",\n",
    "    spec=ServerlessSpec(\n",
    "        cloud=\"aws\",\n",
    "        region=\"us-east-1\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Pinecone index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pc.Index(index_name)\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import uuid\n",
    "\n",
    "# Load the Excel file\n",
    "df = pd.read_csv('data.csv')\n",
    "df = df.fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create vector db context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_combined_string(row):    \n",
    "    combined_string = (\n",
    "        f\"Vulnerability: {row['CVE ID']}\"\n",
    "        f\"\\n\"\n",
    "        f\"Weakness: {row['CWE ID']}\"\n",
    "        f\"\\n\"\n",
    "        f\"Vulnerability Summary: {row['Summary']}\"\n",
    "        f\"\\n\"\n",
    "        f\"Vulnerable Function:{row['func_before']}\"\n",
    "        f\"\\n\"\n",
    "        f\"Vulnerable Function Fix: {row['func_after']}\"\n",
    "    )\n",
    "    return combined_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Data'] = df.apply(create_combined_string, axis=1)\n",
    "data = [{'id': str(uuid.uuid4()), 'context': row['Data']} for index, row in df.iterrows()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dense Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "if device != 'cuda':\n",
    "    print(\"==========\\n\"+\n",
    "          \"WARNING: You are not running on GPU so this may be slow.\\n\"+\n",
    "          \"If on Google Colab, go to top menu > Runtime > Change \"+\n",
    "          \"runtime type > Hardware accelerator > 'GPU' and rerun \"+\n",
    "          \"the notebook.\\n==========\")\n",
    "\n",
    "dense_model = SentenceTransformer(\n",
    "    'msmarco-bert-base-dot-v5',\n",
    "    device=device\n",
    ")\n",
    "\n",
    "dim = dense_model.get_sentence_embedding_dimension()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from splade.models.transformer_rep import Splade\n",
    "\n",
    "sparse_model_id = 'naver/splade-cocondenser-ensembledistil'\n",
    "\n",
    "sparse_model = Splade(sparse_model_id, agg='max')\n",
    "sparse_model.to(device)  \n",
    "sparse_model.eval()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(sparse_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index entire dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "\n",
    "\n",
    "def builder(records: list):\n",
    "    ids = [x['id'] for x in records]\n",
    "    contexts = [x['context'] for x in records]\n",
    "    dense_vecs = dense_model.encode(contexts).tolist()\n",
    "    input_ids = tokenizer(\n",
    "        contexts, return_tensors='pt',\n",
    "        padding=True, truncation=True\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        sparse_vecs = sparse_model(\n",
    "            d_kwargs=input_ids.to(device)\n",
    "        )['d_rep'].squeeze()\n",
    "    upserts = []\n",
    "    for _id, dense_vec, sparse_vec, context in zip(ids, dense_vecs, sparse_vecs, contexts):\n",
    "        indices = sparse_vec.nonzero().squeeze().cpu().tolist()  \n",
    "        values = sparse_vec[indices].cpu().tolist()  \n",
    "        sparse_values = {\n",
    "            \"indices\": indices,\n",
    "            \"values\": values\n",
    "        }\n",
    "        \n",
    "        metadata = {'context': context}\n",
    "        upserts.append({\n",
    "            'id': _id,\n",
    "            'values': dense_vec,\n",
    "            'sparse_values': sparse_values,\n",
    "            'metadata': metadata\n",
    "        })\n",
    "    return upserts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upsert chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "for i in tqdm(range(0, len(data), batch_size)):\n",
    "    i_end = min(i+batch_size, len(data))\n",
    "    batch = data[i:i_end]\n",
    "    index.upsert(builder(data[i:i+batch_size]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text: str):\n",
    "    dense_vec = dense_model.encode(text).tolist()\n",
    "    input_ids = tokenizer(text, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        sparse_vec = sparse_model(\n",
    "            d_kwargs=input_ids.to(device)\n",
    "        )['d_rep'].squeeze()\n",
    "    \n",
    "    indices = sparse_vec.nonzero().squeeze().cpu().tolist()\n",
    "    values = sparse_vec[indices].cpu().tolist()\n",
    "    sparse_dict = {\"indices\": indices, \"values\": values}\n",
    "    \n",
    "    return dense_vec, sparse_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = (\n",
    "    \"Vulnerability: CVE-2014-3173 and Weakness: CWE-119\"\n",
    ")\n",
    "\n",
    "dense, sparse = encode(query)\n",
    "\n",
    "xc = index.query(\n",
    "    vector=dense,\n",
    "    sparse_vector=sparse,\n",
    "    top_k=5,  \n",
    "    include_metadata=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
