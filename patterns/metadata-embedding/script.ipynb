{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install \\\n",
    "  transformers \\\n",
    "  sentence-transformers \\\n",
    "  pinecone-client \\\n",
    "  datasets \\\n",
    "  accelerate \\\n",
    "  einops \\\n",
    "  langchain \\\n",
    "  xformers \\\n",
    "  bitsandbytes \\\n",
    "  langchain-community \\\n",
    "  pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install git+https://github.com/naver/splade.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize HG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import cuda\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embed_model_id = 'sentence-transformers/msmarco-bert-base-dot-v5'\n",
    "\n",
    "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
    "\n",
    "embed_model = HuggingFaceEmbeddings(\n",
    "    model_name=embed_model_id,\n",
    "    model_kwargs={'device': device},\n",
    "    encode_kwargs={'device': device, 'batch_size': 32}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Pinecone index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import os\n",
    "\n",
    "pc = Pinecone(api_key='XXX')\n",
    "index_name = 'metadata-embedding'\n",
    "\n",
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=768, \n",
    "    metric=\"dotproduct\",\n",
    "    spec=ServerlessSpec(\n",
    "        cloud=\"aws\",\n",
    "        region=\"us-east-1\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Pinecone index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pc.Index(index_name)\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import uuid\n",
    "\n",
    "# Load the Excel file\n",
    "df = pd.read_csv('data.csv')\n",
    "df = df.fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create vector db context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\n",
    "        'id': str(uuid.uuid4()),\n",
    "        'cve': row['CVE ID'],\n",
    "        'cwe': row['CWE ID'],\n",
    "        'Summary': row['Summary'],\n",
    "        'func_before': row['func_before'],\n",
    "        'func_after': row['func_after']\n",
    "    } for index, row in df.iterrows()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dense Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "if device != 'cuda':\n",
    "    print(\"==========\\n\"+\n",
    "          \"WARNING: You are not running on GPU so this may be slow.\\n\"+\n",
    "          \"If on Google Colab, go to top menu > Runtime > Change \"+\n",
    "          \"runtime type > Hardware accelerator > 'GPU' and rerun \"+\n",
    "          \"the notebook.\\n==========\")\n",
    "\n",
    "dense_model = SentenceTransformer(\n",
    "    'msmarco-bert-base-dot-v5',\n",
    "    device=device\n",
    ")\n",
    "\n",
    "dim = dense_model.get_sentence_embedding_dimension()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from splade.models.transformer_rep import Splade\n",
    "\n",
    "sparse_model_id = 'naver/splade-cocondenser-ensembledistil'\n",
    "\n",
    "sparse_model = Splade(sparse_model_id, agg='max')\n",
    "sparse_model.to(device)  \n",
    "sparse_model.eval()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(sparse_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index entire dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def encode_field(text):\n",
    "    \"\"\"Encodes a single field using the dense and sparse models.\"\"\"\n",
    "    dense_vec = dense_model.encode([text]).tolist()[0]\n",
    "    input_ids = tokenizer([text], return_tensors='pt', padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        sparse_vec = sparse_model(d_kwargs=input_ids.to(device))['d_rep'].squeeze()\n",
    "    indices = sparse_vec.nonzero().squeeze().cpu().tolist()\n",
    "    values = sparse_vec[indices].cpu().tolist()\n",
    "    sparse_dict = {\"indices\": indices, \"values\": values}\n",
    "    return dense_vec, sparse_dict\n",
    "\n",
    "# Function to encode the combined metadata\n",
    "def encode_metadata(row):\n",
    "    dense_vecs = []\n",
    "    combined_sparse_dict = defaultdict(float)\n",
    "\n",
    "    for field in ['cve', 'cwe', 'Summary', 'func_before', 'func_after']:\n",
    "        text = row[field]\n",
    "        dense_vec, sparse_dict = encode_field(text)\n",
    "        \n",
    "        # Collect dense vectors\n",
    "        dense_vecs.append(dense_vec)\n",
    "        \n",
    "        # Combine sparse vectors and handle duplicate indices by summing their values\n",
    "        for idx, val in zip(sparse_dict['indices'], sparse_dict['values']):\n",
    "            combined_sparse_dict[idx] += val\n",
    "    \n",
    "    # Average dense vectors to match the expected dimension\n",
    "    averaged_dense_vec = [sum(x) / len(dense_vecs) for x in zip(*dense_vecs)]\n",
    "    \n",
    "    # Convert combined sparse dict to indices and values lists\n",
    "    combined_sparse_indices = list(combined_sparse_dict.keys())\n",
    "    combined_sparse_values = list(combined_sparse_dict.values())\n",
    "    \n",
    "    combined_sparse_dict = {\"indices\": combined_sparse_indices, \"values\": combined_sparse_values}\n",
    "    return averaged_dense_vec, combined_sparse_dict\n",
    "\n",
    "\n",
    "def builder(records: list):\n",
    "    # Convert records to upserts format\n",
    "    upserts = []\n",
    "    for record in records:\n",
    "        dense_vec, sparse_dict = encode_metadata(record)\n",
    "        \n",
    "        # Build metadata struct\n",
    "        metadata = {\n",
    "            'cve': record['cve'],\n",
    "            'cwe': record['cwe'],\n",
    "            'Summary': record['Summary'],\n",
    "            'func_before': record['func_before'],\n",
    "            'func_after': record['func_after']\n",
    "        }\n",
    "        \n",
    "        # Append all to upserts list as pinecone.Vector (or GRPCVector)\n",
    "        upserts.append({\n",
    "            'id': record['id'],\n",
    "            'values': dense_vec,\n",
    "            'sparse_values': sparse_dict,\n",
    "            'metadata': metadata\n",
    "        })\n",
    "    \n",
    "    return upserts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upsert chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "for i in tqdm(range(0, len(data), batch_size)):\n",
    "    i_end = min(i+batch_size, len(data))\n",
    "    batch = data[i:i_end]\n",
    "    index.upsert(builder(data[i:i+batch_size]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text: str):\n",
    "    dense_vec = dense_model.encode(text).tolist()\n",
    "    input_ids = tokenizer(text, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        sparse_vec = sparse_model(\n",
    "            d_kwargs=input_ids.to(device)\n",
    "        )['d_rep'].squeeze()\n",
    "    \n",
    "    indices = sparse_vec.nonzero().squeeze().cpu().tolist()\n",
    "    values = sparse_vec[indices].cpu().tolist()\n",
    "    sparse_dict = {\"indices\": indices, \"values\": values}\n",
    "    \n",
    "    return dense_vec, sparse_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = (\n",
    "    \"Vulnerability: CVE-2014-3173 and Weakness: CWE-119\"\n",
    ")\n",
    "\n",
    "dense, sparse = encode(query)\n",
    "\n",
    "xc = index.query(\n",
    "    vector=dense,\n",
    "    sparse_vector=sparse,\n",
    "    top_k=5,  \n",
    "    include_metadata=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
